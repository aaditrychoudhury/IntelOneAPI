{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70422430-353b-4e06-9fea-b6a45bd70799",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downloading Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d463f-3236-425c-a191-e4edbf0981b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz -P pre-trained-models ; tar zxvf pre-trained-models/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz -C pre-trained-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611d8dfd-e73c-4dd6-b508-6c7b223b271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dumping Reuslt in Log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b503b82-fe81-446a-9aab-33b7421593c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In jupyter notebook simple logging to console and file:\n",
    "\"\"\"\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='[{%(filename)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(filename='log.txt'),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d24b780d-d907-4680-beba-74b4fbda6ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Patch benchmark script to enable logging for throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72d0af62-a6fc-4193-a1c4-f41d3f4f8a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd scripts;patch < enable_log.patch;cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a765f5a5-485f-4cf2-8867-376dfd09ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running Benchmark Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3707e72e-3698-438d-a50a-72fdb5968c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-01 19:07:08.667092: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/glob/development-tools/versions/oneapi/2023.1.2/oneapi/intelpython/latest/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2023-07-01 19:07:52.938618: E itex/core/kernels/xpu_kernel.cc:38] XPU-GPU kernel not supported.\n",
      "If you need help, create an issue at https://github.com/intel/intel-extension-for-tensorflow/issues\n",
      "2023-07-01 19:08:13.078176: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type CPU is enabled.\n",
      "2023-07-01 19:08:13.752037: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'unused_control_flow_input_3' with dtype int32 and shape [1]\n",
      "\t [[{{node unused_control_flow_input_3}}]]\n",
      "2023-07-01 19:08:13.768433: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'unused_control_flow_input_19' with dtype int32 and shape [1]\n",
      "\t [[{{node unused_control_flow_input_19}}]]\n",
      "2023-07-01 19:08:13.769797: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'unused_control_flow_input_22' with dtype int32 and shape [1]\n",
      "\t [[{{node unused_control_flow_input_22}}]]\n",
      "Available Signatures:\n",
      "_SignatureMap({'serving_default': <ConcreteFunction pruned(input_tensor) at 0x7FD7F5881100>})\n",
      "2023-07-01 19:08:15.312724: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type CPU is enabled.\n",
      "Iteration: 5 - Inference Time: 0.583 sec\n",
      "Iteration: 6 - Inference Time: 0.619 sec\n",
      "Iteration: 7 - Inference Time: 0.608 sec\n",
      "Iteration: 8 - Inference Time: 0.605 sec\n",
      "Iteration: 9 - Inference Time: 0.598 sec\n",
      "Iteration: 10 - Inference Time: 0.569 sec\n",
      "Iteration: 11 - Inference Time: 0.579 sec\n",
      "Iteration: 12 - Inference Time: 0.598 sec\n",
      "Iteration: 13 - Inference Time: 0.570 sec\n",
      "Iteration: 14 - Inference Time: 0.594 sec\n",
      "Batch size = 2\n",
      "Latency: 592.197 ms\n",
      "Throughput: 3.377 images/sec\n"
     ]
    }
   ],
   "source": [
    "! python scripts/benchmark.py -m ./pre-trained-models/my_model/optimized_model_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b94c5-931c-4bfa-8e00-569fed3de6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "904fde9c-a39a-4f2f-89a8-4d95f161ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Parse the logfile for performance numberÂ¶\n",
    "# We parse out the performance number from log.txt and save it for later performance comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5f17b40-1d0d-4416-8fb5-6cc831c8b618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get throughput\n",
      "ERROR! can't find correct performance number from log. please check log for runtime issues\n"
     ]
    }
   ],
   "source": [
    "from scripts.profile_utils import PerfPresenter\n",
    "perfp=PerfPresenter()\n",
    "Thoughput_list = []\n",
    "print(\"get throughput\")\n",
    "val = 'Throughput'\n",
    "index = 4\n",
    "line = perfp.read_throughput('log.txt', keyword=val, index=index)\n",
    "if line != None:\n",
    "    throughput=line\n",
    "    print(\"throughput : \" , throughput)\n",
    "    Thoughput_list.append(float(throughput))\n",
    "else:\n",
    "    print(\"ERROR! can't find correct performance number from log. please check log for runtime issues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72489844-bd64-461f-b443-9118d1013fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u192685/Custom_Object_detection\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18463c3d-dcaa-460e-86a7-febc24d23be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optmising Pre Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4cfb4c-1d1e-4e2d-a0b8-43d9582de0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 20:25:16 [WARNING] Force convert framework model to neural_compressor model.\n",
      "2023-06-29 20:25:16.484022: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-29 20:25:22.300793: E itex/core/kernels/xpu_kernel.cc:38] XPU-GPU kernel not supported.\n",
      "If you need help, create an issue at https://github.com/intel/intel-extension-for-tensorflow/issues\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 20:25:25 [WARNING] Output tensor names should not be empty.\n",
      "2023-06-29 20:25:25 [WARNING] Input tensor names is empty.\n",
      "2023-06-29 20:25:30.854451: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= \n",
      "2023-06-29 20:25:30.854645: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-29 20:25:35.486087: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= \n",
      "2023-06-29 20:25:35.486309: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 20:25:39 [INFO] ConvertLayoutOptimizer elapsed time: 0.57 ms\n",
      "2023-06-29 20:25:39 [INFO] Pass ConvertPlaceholderToConst elapsed time: 82.74 ms\n",
      "2023-06-29 20:25:39 [INFO] Pass SwitchOptimizer elapsed time: 80.98 ms\n",
      "2023-06-29 20:25:40.362231: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= \n",
      "2023-06-29 20:25:40.362423: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-29 20:25:41 [INFO] Pass GrapplerOptimizer elapsed time: 1480.23 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/u192685/.local/lib/python3.9/site-packages/neural_compressor/adaptor/tf_utils/util.py:366: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 20:25:41 [INFO] Pass StripUnusedNodesOptimizer elapsed time: 234.17 ms\n",
      "2023-06-29 20:25:41 [INFO] Pass RemoveTrainingNodesOptimizer elapsed time: 81.46 ms\n",
      "2023-06-29 20:25:41 [INFO] Pass SplitSharedInputOptimizer elapsed time: 86.32 ms\n",
      "2023-06-29 20:25:41 [INFO] Pass GraphFoldConstantOptimizer elapsed time: 78.14 ms\n",
      "2023-06-29 20:25:41 [INFO] Pass FuseDecomposedBNOptimizer elapsed time: 152.68 ms\n",
      "2023-06-29 20:25:41 [INFO] Pass FuseColumnWiseMulOptimizer elapsed time: 82.4 ms\n",
      "2023-06-29 20:25:42 [INFO] Pass StripUnusedNodesOptimizer elapsed time: 235.35 ms\n",
      "2023-06-29 20:25:42 [INFO] Pass GraphCseOptimizer elapsed time: 83.49 ms\n",
      "2023-06-29 20:25:42 [INFO] Pass FoldBatchNormNodesOptimizer elapsed time: 416.69 ms\n",
      "2023-06-29 20:25:42 [INFO] Pass RenameBatchNormOptimizer elapsed time: 85.07 ms\n",
      "2023-06-29 20:25:42 [INFO] Pass ConvertLeakyReluOptimizer elapsed time: 82.47 ms\n",
      "2023-06-29 20:25:42 [INFO] Pass ConvertAddToBiasAddOptimizer elapsed time: 81.76 ms\n",
      "2023-06-29 20:25:43 [INFO] Pass FuseTransposeReshapeOptimizer elapsed time: 83.51 ms\n",
      "2023-06-29 20:25:43 [INFO] Pass FuseConvWithMathOptimizer elapsed time: 81.78 ms\n",
      "2023-06-29 20:25:43 [INFO] Pass ExpandDimsOptimizer elapsed time: 82.45 ms\n",
      "2023-06-29 20:25:43 [INFO] Pass FetchWeightFromReshapeOptimizer elapsed time: 81.89 ms\n",
      "2023-06-29 20:25:43 [INFO] Pass MoveSqueezeAfterReluOptimizer elapsed time: 84.05 ms\n",
      "2023-06-29 20:25:43 [WARNING] Found possible input node names: ['input_tensor'], output node names: ['Identity_6', 'Identity_7', 'Identity_5', 'Identity_1', 'Identity_3', 'Identity_4', 'Identity_2', 'Identity'].\n",
      "2023-06-29 20:25:43 [INFO] Pass InjectDummyBiasAddOptimizer elapsed time: 89.59 ms\n",
      "2023-06-29 20:25:44 [WARNING] All replaced equivalent node types are {}\n",
      "2023-06-29 20:25:44 [INFO] Pass StripEquivalentNodesOptimizer elapsed time: 406.18 ms\n",
      "2023-06-29 20:25:44 [INFO] Pass Pre Optimization elapsed time: 5634.97 ms\n",
      "2023-06-29 20:25:46 [INFO] Adaptor has 3 recipes.\n",
      "2023-06-29 20:25:46 [INFO] 0 recipes specified by user.\n",
      "2023-06-29 20:25:46 [INFO] 2 recipes require future tuning.\n",
      "2023-06-29 20:25:46 [INFO] Neither evaluation function nor metric is defined. Generate a quantized model with default quantization configuration.\n",
      "2023-06-29 20:25:46 [INFO] Force setting 'tuning.exit_policy.performance_only = True'.\n",
      "2023-06-29 20:25:46 [WARNING] Please note the 2.12.0 version of TensorFlow is not fully verified! Suggest to use the versions between 1.14.0 and 2.11.0 if meet problem.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 20:25:47 [WARNING] Found possible input node names: ['input_tensor'], output node names: ['Identity_6', 'Identity_7', 'Identity_5', 'Identity_1', 'Identity_3', 'Identity_4', 'Identity_2', 'Identity'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 20:25:48 [WARNING] Found possible input node names: ['input_tensor'], output node names: ['Identity_6', 'Identity_7', 'Identity_5', 'Identity_1', 'Identity_3', 'Identity_4', 'Identity_2', 'Identity'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 20:26:07 [INFO] Pass PostCseOptimizer elapsed time: 19093.98 ms\n",
      "2023-06-29 20:26:07 [INFO] Pass PostHostConstConverter elapsed time: 171.3 ms\n",
      "2023-06-29 20:26:08 [INFO] |******Mixed Precision Statistics******|\n",
      "2023-06-29 20:26:08 [INFO] +----------------+----------+----------+\n",
      "2023-06-29 20:26:08 [INFO] |    Op Type     |  Total   |   FP32   |\n",
      "2023-06-29 20:26:08 [INFO] +----------------+----------+----------+\n",
      "2023-06-29 20:26:08 [INFO] |    AvgPool     |    1     |    1     |\n",
      "2023-06-29 20:26:08 [INFO] |     MatMul     |    2     |    2     |\n",
      "2023-06-29 20:26:08 [INFO] |    MaxPool     |    2     |    2     |\n",
      "2023-06-29 20:26:08 [INFO] |    ConcatV2    |    12    |    12    |\n",
      "2023-06-29 20:26:08 [INFO] |     Conv2D     |    56    |    56    |\n",
      "2023-06-29 20:26:08 [INFO] |      Cast      |    12    |    12    |\n",
      "2023-06-29 20:26:08 [INFO] +----------------+----------+----------+\n",
      "2023-06-29 20:26:08 [INFO] Pass quantize model elapsed time: 22407.36 ms\n",
      "2023-06-29 20:26:08 [INFO] Save tuning history to /home/u192685/Custom_Object_detection/nc_workspace/2023-06-29_20-25-15/./history.snapshot.\n",
      "2023-06-29 20:26:08 [INFO] Specified timeout or max trials is reached! Found a converted model which meet accuracy goal. Exit.\n",
      "2023-06-29 20:26:08 [INFO] Save deploy yaml to /home/u192685/Custom_Object_detection/nc_workspace/2023-06-29_20-25-15/deploy.yaml\n",
      "2023-06-29 20:26:08 [INFO] Graph optimization is done. Please invoke model.save() to save optimized model to disk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/u192685/.local/lib/python3.9/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:203: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/u192685/Custom_Object_detection/pre-trained-models/my_model/optimized_model_inc/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 20:26:10 [INFO] Save quantized model to /home/u192685/Custom_Object_detection/pre-trained-models/my_model/optimized_model_inc.\n"
     ]
    }
   ],
   "source": [
    "from neural_compressor.experimental import Graph_Optimization\n",
    "graph_opt = Graph_Optimization()\n",
    "graph_opt.model = 'pre-trained-models/my_model/saved_model'   # the path to saved_model dir\n",
    "output = graph_opt()\n",
    "output.save('pre-trained-models/my_model/optimized_model_inc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84faeb23-976a-4a74-9a04-82d11bb46b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-29 20:30:22.454445: E itex/core/kernels/xpu_kernel.cc:38] XPU-GPU kernel not supported.\n",
      "If you need help, create an issue at https://github.com/intel/intel-extension-for-tensorflow/issues\n",
      "Available Signatures:\n",
      "_SignatureMap({'serving_default': <ConcreteFunction pruned(input_tensor) at 0x7F0D0F702A60>})\n",
      "Iteration: 5 - Inference Time: 0.530 sec\n",
      "Iteration: 6 - Inference Time: 0.499 sec\n",
      "Iteration: 7 - Inference Time: 0.500 sec\n",
      "Iteration: 8 - Inference Time: 0.506 sec\n",
      "Iteration: 9 - Inference Time: 0.524 sec\n",
      "Iteration: 10 - Inference Time: 0.523 sec\n",
      "Iteration: 11 - Inference Time: 0.515 sec\n",
      "Iteration: 12 - Inference Time: 0.490 sec\n",
      "Iteration: 13 - Inference Time: 0.514 sec\n",
      "Iteration: 14 - Inference Time: 0.530 sec\n",
      "Batch size = 1\n",
      "Latency: 513.129 ms\n",
      "Throughput: 1.949 images/sec\n"
     ]
    }
   ],
   "source": [
    "! python ./scripts/benchmark.py -m ./pre-trained-models/my_model/optimized_model_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a5ce23-7000-4542-912f-e9d9a8cf52ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 21:53:12.586628: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-27 21:53:56.347808: E itex/core/kernels/xpu_kernel.cc:38] XPU-GPU kernel not supported.\n",
      "If you need help, create an issue at https://github.com/intel/intel-extension-for-tensorflow/issues\n",
      "Available Signatures:\n",
      "_SignatureMap({'serving_default': <ConcreteFunction signature_wrapper(*, input_tensor) at 0x7F35D8193100>})\n",
      "2023-06-27 21:54:19.755009: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type CPU is enabled.\n",
      "Iteration: 5 - Inference Time: 0.518 sec\n",
      "Iteration: 6 - Inference Time: 0.559 sec\n",
      "Iteration: 7 - Inference Time: 0.562 sec\n",
      "Iteration: 8 - Inference Time: 0.551 sec\n",
      "Iteration: 9 - Inference Time: 0.547 sec\n",
      "Iteration: 10 - Inference Time: 0.529 sec\n",
      "Iteration: 11 - Inference Time: 0.547 sec\n",
      "Iteration: 12 - Inference Time: 0.537 sec\n",
      "Iteration: 13 - Inference Time: 0.526 sec\n",
      "Iteration: 14 - Inference Time: 0.553 sec\n",
      "Iteration: 15 - Inference Time: 0.558 sec\n",
      "Iteration: 16 - Inference Time: 0.525 sec\n",
      "Iteration: 17 - Inference Time: 0.547 sec\n",
      "Iteration: 18 - Inference Time: 0.548 sec\n",
      "Iteration: 19 - Inference Time: 0.575 sec\n",
      "Iteration: 20 - Inference Time: 0.542 sec\n",
      "Iteration: 21 - Inference Time: 0.567 sec\n",
      "Iteration: 22 - Inference Time: 0.569 sec\n",
      "Iteration: 23 - Inference Time: 0.561 sec\n",
      "Iteration: 24 - Inference Time: 0.564 sec\n",
      "Iteration: 25 - Inference Time: 0.591 sec\n",
      "Iteration: 26 - Inference Time: 0.564 sec\n",
      "Iteration: 27 - Inference Time: 0.555 sec\n",
      "Iteration: 28 - Inference Time: 0.563 sec\n",
      "Iteration: 29 - Inference Time: 0.551 sec\n",
      "Iteration: 30 - Inference Time: 0.561 sec\n",
      "Iteration: 31 - Inference Time: 0.558 sec\n",
      "Iteration: 32 - Inference Time: 0.548 sec\n",
      "Iteration: 33 - Inference Time: 0.545 sec\n",
      "Iteration: 34 - Inference Time: 0.526 sec\n",
      "Iteration: 35 - Inference Time: 0.563 sec\n",
      "Iteration: 36 - Inference Time: 0.548 sec\n",
      "Iteration: 37 - Inference Time: 0.588 sec\n",
      "Iteration: 38 - Inference Time: 0.539 sec\n",
      "Iteration: 39 - Inference Time: 0.552 sec\n",
      "Iteration: 40 - Inference Time: 0.548 sec\n",
      "Iteration: 41 - Inference Time: 0.546 sec\n",
      "Iteration: 42 - Inference Time: 0.543 sec\n",
      "Iteration: 43 - Inference Time: 0.549 sec\n",
      "Iteration: 44 - Inference Time: 0.535 sec\n",
      "Iteration: 45 - Inference Time: 0.528 sec\n",
      "Iteration: 46 - Inference Time: 0.578 sec\n",
      "Iteration: 47 - Inference Time: 0.553 sec\n",
      "Iteration: 48 - Inference Time: 0.563 sec\n",
      "Iteration: 49 - Inference Time: 0.538 sec\n",
      "Iteration: 50 - Inference Time: 0.552 sec\n",
      "Iteration: 51 - Inference Time: 0.537 sec\n",
      "Iteration: 52 - Inference Time: 0.544 sec\n",
      "Iteration: 53 - Inference Time: 0.540 sec\n",
      "Iteration: 54 - Inference Time: 0.560 sec\n",
      "Iteration: 55 - Inference Time: 0.561 sec\n",
      "Iteration: 56 - Inference Time: 0.577 sec\n",
      "Iteration: 57 - Inference Time: 0.573 sec\n",
      "Iteration: 58 - Inference Time: 0.534 sec\n",
      "Iteration: 59 - Inference Time: 0.566 sec\n",
      "Iteration: 60 - Inference Time: 0.559 sec\n",
      "Iteration: 61 - Inference Time: 0.581 sec\n",
      "Iteration: 62 - Inference Time: 0.522 sec\n",
      "Iteration: 63 - Inference Time: 0.548 sec\n",
      "Iteration: 64 - Inference Time: 0.529 sec\n",
      "Iteration: 65 - Inference Time: 0.535 sec\n",
      "Iteration: 66 - Inference Time: 0.546 sec\n",
      "Iteration: 67 - Inference Time: 0.534 sec\n",
      "Iteration: 68 - Inference Time: 0.546 sec\n",
      "Iteration: 69 - Inference Time: 0.531 sec\n",
      "Iteration: 70 - Inference Time: 0.544 sec\n",
      "Iteration: 71 - Inference Time: 0.522 sec\n",
      "Iteration: 72 - Inference Time: 0.534 sec\n",
      "Iteration: 73 - Inference Time: 0.555 sec\n",
      "Iteration: 74 - Inference Time: 0.560 sec\n",
      "Iteration: 75 - Inference Time: 0.535 sec\n",
      "Iteration: 76 - Inference Time: 0.539 sec\n",
      "Iteration: 77 - Inference Time: 0.562 sec\n",
      "Iteration: 78 - Inference Time: 0.543 sec\n",
      "Iteration: 79 - Inference Time: 0.556 sec\n",
      "Iteration: 80 - Inference Time: 0.527 sec\n",
      "Iteration: 81 - Inference Time: 0.539 sec\n",
      "Iteration: 82 - Inference Time: 0.526 sec\n",
      "Iteration: 83 - Inference Time: 0.536 sec\n",
      "Iteration: 84 - Inference Time: 0.569 sec\n",
      "Iteration: 85 - Inference Time: 0.548 sec\n",
      "Iteration: 86 - Inference Time: 0.548 sec\n",
      "Iteration: 87 - Inference Time: 0.542 sec\n",
      "Iteration: 88 - Inference Time: 0.596 sec\n",
      "Iteration: 89 - Inference Time: 0.528 sec\n",
      "Iteration: 90 - Inference Time: 0.544 sec\n",
      "Iteration: 91 - Inference Time: 0.550 sec\n",
      "Iteration: 92 - Inference Time: 0.567 sec\n",
      "Iteration: 93 - Inference Time: 0.535 sec\n",
      "Iteration: 94 - Inference Time: 0.525 sec\n",
      "Iteration: 95 - Inference Time: 0.541 sec\n",
      "Iteration: 96 - Inference Time: 0.551 sec\n",
      "Iteration: 97 - Inference Time: 0.544 sec\n",
      "Iteration: 98 - Inference Time: 0.566 sec\n",
      "Iteration: 99 - Inference Time: 0.529 sec\n",
      "Iteration: 100 - Inference Time: 0.529 sec\n",
      "Iteration: 101 - Inference Time: 0.539 sec\n",
      "Iteration: 102 - Inference Time: 0.551 sec\n",
      "Iteration: 103 - Inference Time: 0.595 sec\n",
      "Iteration: 104 - Inference Time: 0.537 sec\n",
      "Batch size = 1\n",
      "Latency: 549.020 ms\n",
      "Throughput: 1.821 images/sec\n"
     ]
    }
   ],
   "source": [
    "! python ./scripts/benchmark.py -m ./pre-trained-models/fineTuned_Model/saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae432c4-3cd7-473f-9c42-3b5643a793cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 21:55:53 [WARNING] Force convert framework model to neural_compressor model.\n",
      "2023-06-27 21:55:54.169851: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-27 21:55:59.124046: E itex/core/kernels/xpu_kernel.cc:38] XPU-GPU kernel not supported.\n",
      "If you need help, create an issue at https://github.com/intel/intel-extension-for-tensorflow/issues\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 21:56:02 [WARNING] Output tensor names should not be empty.\n",
      "2023-06-27 21:56:02 [WARNING] Input tensor names is empty.\n",
      "2023-06-27 21:56:07.856018: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= \n",
      "2023-06-27 21:56:07.856198: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-27 21:56:12.414412: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= \n",
      "2023-06-27 21:56:12.414596: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 21:56:16 [INFO] ConvertLayoutOptimizer elapsed time: 0.55 ms\n",
      "2023-06-27 21:56:16 [INFO] Pass ConvertPlaceholderToConst elapsed time: 80.79 ms\n",
      "2023-06-27 21:56:16 [INFO] Pass SwitchOptimizer elapsed time: 81.79 ms\n",
      "2023-06-27 21:56:17.312828: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= \n",
      "2023-06-27 21:56:17.313015: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-27 21:56:18 [INFO] Pass GrapplerOptimizer elapsed time: 1478.62 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/u192685/.local/lib/python3.9/site-packages/neural_compressor/adaptor/tf_utils/util.py:366: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 21:56:18 [INFO] Pass StripUnusedNodesOptimizer elapsed time: 231.28 ms\n",
      "2023-06-27 21:56:18 [INFO] Pass RemoveTrainingNodesOptimizer elapsed time: 80.27 ms\n",
      "2023-06-27 21:56:18 [INFO] Pass SplitSharedInputOptimizer elapsed time: 85.18 ms\n",
      "2023-06-27 21:56:18 [INFO] Pass GraphFoldConstantOptimizer elapsed time: 77.14 ms\n",
      "2023-06-27 21:56:18 [INFO] Pass FuseDecomposedBNOptimizer elapsed time: 150.85 ms\n",
      "2023-06-27 21:56:18 [INFO] Pass FuseColumnWiseMulOptimizer elapsed time: 81.9 ms\n",
      "2023-06-27 21:56:19 [INFO] Pass StripUnusedNodesOptimizer elapsed time: 238.32 ms\n",
      "2023-06-27 21:56:19 [INFO] Pass GraphCseOptimizer elapsed time: 82.97 ms\n",
      "2023-06-27 21:56:19 [INFO] Pass FoldBatchNormNodesOptimizer elapsed time: 438.31 ms\n",
      "2023-06-27 21:56:19 [INFO] Pass RenameBatchNormOptimizer elapsed time: 83.59 ms\n",
      "2023-06-27 21:56:19 [INFO] Pass ConvertLeakyReluOptimizer elapsed time: 81.17 ms\n",
      "2023-06-27 21:56:19 [INFO] Pass ConvertAddToBiasAddOptimizer elapsed time: 80.92 ms\n",
      "2023-06-27 21:56:19 [INFO] Pass FuseTransposeReshapeOptimizer elapsed time: 81.79 ms\n",
      "2023-06-27 21:56:20 [INFO] Pass FuseConvWithMathOptimizer elapsed time: 80.96 ms\n",
      "2023-06-27 21:56:20 [INFO] Pass ExpandDimsOptimizer elapsed time: 81.36 ms\n",
      "2023-06-27 21:56:20 [INFO] Pass FetchWeightFromReshapeOptimizer elapsed time: 81.01 ms\n",
      "2023-06-27 21:56:20 [INFO] Pass MoveSqueezeAfterReluOptimizer elapsed time: 81.22 ms\n",
      "2023-06-27 21:56:20 [WARNING] Found possible input node names: ['input_tensor'], output node names: ['Identity_6', 'Identity_7', 'Identity_5', 'Identity_1', 'Identity_3', 'Identity_4', 'Identity_2', 'Identity'].\n",
      "2023-06-27 21:56:20 [INFO] Pass InjectDummyBiasAddOptimizer elapsed time: 88.18 ms\n",
      "2023-06-27 21:56:21 [WARNING] All replaced equivalent node types are {}\n",
      "2023-06-27 21:56:21 [INFO] Pass StripEquivalentNodesOptimizer elapsed time: 406.17 ms\n",
      "2023-06-27 21:56:21 [INFO] Pass Pre Optimization elapsed time: 5660.75 ms\n",
      "2023-06-27 21:56:23 [INFO] Adaptor has 3 recipes.\n",
      "2023-06-27 21:56:23 [INFO] 0 recipes specified by user.\n",
      "2023-06-27 21:56:23 [INFO] 2 recipes require future tuning.\n",
      "2023-06-27 21:56:23 [INFO] Neither evaluation function nor metric is defined. Generate a quantized model with default quantization configuration.\n",
      "2023-06-27 21:56:23 [INFO] Force setting 'tuning.exit_policy.performance_only = True'.\n",
      "2023-06-27 21:56:23 [WARNING] Please note the 2.12.0 version of TensorFlow is not fully verified! Suggest to use the versions between 1.14.0 and 2.11.0 if meet problem.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 21:56:24 [WARNING] Found possible input node names: ['input_tensor'], output node names: ['Identity_6', 'Identity_7', 'Identity_5', 'Identity_1', 'Identity_3', 'Identity_4', 'Identity_2', 'Identity'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 21:56:25 [WARNING] Found possible input node names: ['input_tensor'], output node names: ['Identity_6', 'Identity_7', 'Identity_5', 'Identity_1', 'Identity_3', 'Identity_4', 'Identity_2', 'Identity'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 21:56:42 [INFO] Pass PostCseOptimizer elapsed time: 16523.57 ms\n",
      "2023-06-27 21:56:42 [INFO] Pass PostHostConstConverter elapsed time: 176.17 ms\n",
      "2023-06-27 21:56:43 [INFO] |******Mixed Precision Statistics******|\n",
      "2023-06-27 21:56:43 [INFO] +----------------+----------+----------+\n",
      "2023-06-27 21:56:43 [INFO] |    Op Type     |  Total   |   FP32   |\n",
      "2023-06-27 21:56:43 [INFO] +----------------+----------+----------+\n",
      "2023-06-27 21:56:43 [INFO] |     Conv2D     |    56    |    56    |\n",
      "2023-06-27 21:56:43 [INFO] |    MaxPool     |    2     |    2     |\n",
      "2023-06-27 21:56:43 [INFO] |     MatMul     |    2     |    2     |\n",
      "2023-06-27 21:56:43 [INFO] |    AvgPool     |    1     |    1     |\n",
      "2023-06-27 21:56:43 [INFO] |    ConcatV2    |    12    |    12    |\n",
      "2023-06-27 21:56:43 [INFO] |      Cast      |    12    |    12    |\n",
      "2023-06-27 21:56:43 [INFO] +----------------+----------+----------+\n",
      "2023-06-27 21:56:43 [INFO] Pass quantize model elapsed time: 19845.46 ms\n",
      "2023-06-27 21:56:43 [INFO] Save tuning history to /home/u192685/Custom_Object_detection/nc_workspace/2023-06-27_21-55-53/./history.snapshot.\n",
      "2023-06-27 21:56:43 [INFO] Specified timeout or max trials is reached! Found a converted model which meet accuracy goal. Exit.\n",
      "2023-06-27 21:56:43 [INFO] Save deploy yaml to /home/u192685/Custom_Object_detection/nc_workspace/2023-06-27_21-55-53/deploy.yaml\n",
      "2023-06-27 21:56:43 [INFO] Graph optimization is done. Please invoke model.save() to save optimized model to disk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/u192685/.local/lib/python3.9/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:203: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/u192685/Custom_Object_detection/pre-trained-models/fineTuned_Model/optimized_model_inc/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 21:56:45 [INFO] Save quantized model to /home/u192685/Custom_Object_detection/pre-trained-models/fineTuned_Model/optimized_model_inc.\n"
     ]
    }
   ],
   "source": [
    "from neural_compressor.experimental import Graph_Optimization\n",
    "graph_opt = Graph_Optimization()\n",
    "graph_opt.model = 'pre-trained-models/fineTuned_Model/saved_model'   # the path to saved_model dir\n",
    "output = graph_opt()\n",
    "output.save('pre-trained-models/fineTuned_Model/optimized_model_inc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77d071cb-4dab-408a-9e8a-c97600f01045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 21:57:20.350720: E itex/core/kernels/xpu_kernel.cc:38] XPU-GPU kernel not supported.\n",
      "If you need help, create an issue at https://github.com/intel/intel-extension-for-tensorflow/issues\n",
      "Available Signatures:\n",
      "_SignatureMap({'serving_default': <ConcreteFunction pruned(input_tensor) at 0x7F4BB5AE8A60>})\n",
      "Iteration: 5 - Inference Time: 0.572 sec\n",
      "Iteration: 6 - Inference Time: 0.544 sec\n",
      "Iteration: 7 - Inference Time: 0.547 sec\n",
      "Iteration: 8 - Inference Time: 0.535 sec\n",
      "Iteration: 9 - Inference Time: 0.574 sec\n",
      "Iteration: 10 - Inference Time: 0.553 sec\n",
      "Iteration: 11 - Inference Time: 0.550 sec\n",
      "Iteration: 12 - Inference Time: 0.543 sec\n",
      "Iteration: 13 - Inference Time: 0.558 sec\n",
      "Iteration: 14 - Inference Time: 0.568 sec\n",
      "Iteration: 15 - Inference Time: 0.554 sec\n",
      "Iteration: 16 - Inference Time: 0.562 sec\n",
      "Iteration: 17 - Inference Time: 0.564 sec\n",
      "Iteration: 18 - Inference Time: 0.570 sec\n",
      "Iteration: 19 - Inference Time: 0.552 sec\n",
      "Iteration: 20 - Inference Time: 0.570 sec\n",
      "Iteration: 21 - Inference Time: 0.565 sec\n",
      "Iteration: 22 - Inference Time: 0.553 sec\n",
      "Iteration: 23 - Inference Time: 0.559 sec\n",
      "Iteration: 24 - Inference Time: 0.554 sec\n",
      "Iteration: 25 - Inference Time: 0.560 sec\n",
      "Iteration: 26 - Inference Time: 0.555 sec\n",
      "Iteration: 27 - Inference Time: 0.550 sec\n",
      "Iteration: 28 - Inference Time: 0.532 sec\n",
      "Iteration: 29 - Inference Time: 0.547 sec\n",
      "Iteration: 30 - Inference Time: 0.524 sec\n",
      "Iteration: 31 - Inference Time: 0.596 sec\n",
      "Iteration: 32 - Inference Time: 0.573 sec\n",
      "Iteration: 33 - Inference Time: 0.550 sec\n",
      "Iteration: 34 - Inference Time: 0.548 sec\n",
      "Iteration: 35 - Inference Time: 0.532 sec\n",
      "Iteration: 36 - Inference Time: 0.571 sec\n",
      "Iteration: 37 - Inference Time: 0.557 sec\n",
      "Iteration: 38 - Inference Time: 0.569 sec\n",
      "Iteration: 39 - Inference Time: 0.561 sec\n",
      "Iteration: 40 - Inference Time: 0.565 sec\n",
      "Iteration: 41 - Inference Time: 0.559 sec\n",
      "Iteration: 42 - Inference Time: 0.590 sec\n",
      "Iteration: 43 - Inference Time: 0.569 sec\n",
      "Iteration: 44 - Inference Time: 0.544 sec\n",
      "Iteration: 45 - Inference Time: 0.538 sec\n",
      "Iteration: 46 - Inference Time: 0.583 sec\n",
      "Iteration: 47 - Inference Time: 0.542 sec\n",
      "Iteration: 48 - Inference Time: 0.545 sec\n",
      "Iteration: 49 - Inference Time: 0.547 sec\n",
      "Iteration: 50 - Inference Time: 0.602 sec\n",
      "Iteration: 51 - Inference Time: 0.555 sec\n",
      "Iteration: 52 - Inference Time: 0.529 sec\n",
      "Iteration: 53 - Inference Time: 0.534 sec\n",
      "Iteration: 54 - Inference Time: 0.570 sec\n",
      "Iteration: 55 - Inference Time: 0.555 sec\n",
      "Iteration: 56 - Inference Time: 0.533 sec\n",
      "Iteration: 57 - Inference Time: 0.541 sec\n",
      "Iteration: 58 - Inference Time: 0.541 sec\n",
      "Iteration: 59 - Inference Time: 0.556 sec\n",
      "Iteration: 60 - Inference Time: 0.541 sec\n",
      "Iteration: 61 - Inference Time: 0.548 sec\n",
      "Iteration: 62 - Inference Time: 0.545 sec\n",
      "Iteration: 63 - Inference Time: 0.533 sec\n",
      "Iteration: 64 - Inference Time: 0.546 sec\n",
      "Iteration: 65 - Inference Time: 0.533 sec\n",
      "Iteration: 66 - Inference Time: 0.552 sec\n",
      "Iteration: 67 - Inference Time: 0.553 sec\n",
      "Iteration: 68 - Inference Time: 0.541 sec\n",
      "Iteration: 69 - Inference Time: 0.541 sec\n",
      "Iteration: 70 - Inference Time: 0.555 sec\n",
      "Iteration: 71 - Inference Time: 0.568 sec\n",
      "Iteration: 72 - Inference Time: 0.585 sec\n",
      "Iteration: 73 - Inference Time: 0.554 sec\n",
      "Iteration: 74 - Inference Time: 0.543 sec\n",
      "Iteration: 75 - Inference Time: 0.557 sec\n",
      "Iteration: 76 - Inference Time: 0.579 sec\n",
      "Iteration: 77 - Inference Time: 0.540 sec\n",
      "Iteration: 78 - Inference Time: 0.560 sec\n",
      "Iteration: 79 - Inference Time: 0.579 sec\n",
      "Iteration: 80 - Inference Time: 0.540 sec\n",
      "Iteration: 81 - Inference Time: 0.559 sec\n",
      "Iteration: 82 - Inference Time: 0.561 sec\n",
      "Iteration: 83 - Inference Time: 0.560 sec\n",
      "Iteration: 84 - Inference Time: 0.573 sec\n",
      "Iteration: 85 - Inference Time: 0.558 sec\n",
      "Iteration: 86 - Inference Time: 0.564 sec\n",
      "Iteration: 87 - Inference Time: 0.566 sec\n",
      "Iteration: 88 - Inference Time: 0.567 sec\n",
      "Iteration: 89 - Inference Time: 0.565 sec\n",
      "Iteration: 90 - Inference Time: 0.535 sec\n",
      "Iteration: 91 - Inference Time: 0.556 sec\n",
      "Iteration: 92 - Inference Time: 0.560 sec\n",
      "Iteration: 93 - Inference Time: 0.559 sec\n",
      "Iteration: 94 - Inference Time: 0.557 sec\n",
      "Iteration: 95 - Inference Time: 0.564 sec\n",
      "Iteration: 96 - Inference Time: 0.551 sec\n",
      "Iteration: 97 - Inference Time: 0.591 sec\n",
      "Iteration: 98 - Inference Time: 0.551 sec\n",
      "Iteration: 99 - Inference Time: 0.543 sec\n",
      "Iteration: 100 - Inference Time: 0.557 sec\n",
      "Iteration: 101 - Inference Time: 0.558 sec\n",
      "Iteration: 102 - Inference Time: 0.559 sec\n",
      "Iteration: 103 - Inference Time: 0.540 sec\n",
      "Iteration: 104 - Inference Time: 0.535 sec\n",
      "Batch size = 1\n",
      "Latency: 555.495 ms\n",
      "Throughput: 1.800 images/sec\n"
     ]
    }
   ],
   "source": [
    "! python ./scripts/benchmark.py -m ./pre-trained-models/fineTuned_Model/optimized_model_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c3a6d3-8ee3-46ec-aa13-19d3a59c4281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-27 22:02:10.462709: E itex/core/kernels/xpu_kernel.cc:38] XPU-GPU kernel not supported.\n",
      "If you need help, create an issue at https://github.com/intel/intel-extension-for-tensorflow/issues\n",
      "Available Signatures:\n",
      "_SignatureMap({'serving_default': <ConcreteFunction pruned(input_tensor) at 0x7F260740BA60>})\n",
      "Iteration: 5 - Inference Time: 0.586 sec\n",
      "Iteration: 6 - Inference Time: 0.581 sec\n",
      "Iteration: 7 - Inference Time: 0.581 sec\n",
      "Iteration: 8 - Inference Time: 0.575 sec\n",
      "Iteration: 9 - Inference Time: 0.545 sec\n",
      "Iteration: 10 - Inference Time: 0.614 sec\n",
      "Iteration: 11 - Inference Time: 0.563 sec\n",
      "Iteration: 12 - Inference Time: 0.552 sec\n",
      "Iteration: 13 - Inference Time: 0.575 sec\n",
      "Iteration: 14 - Inference Time: 0.566 sec\n",
      "Iteration: 15 - Inference Time: 0.595 sec\n",
      "Iteration: 16 - Inference Time: 0.561 sec\n",
      "Iteration: 17 - Inference Time: 0.549 sec\n",
      "Iteration: 18 - Inference Time: 0.586 sec\n",
      "Iteration: 19 - Inference Time: 0.606 sec\n",
      "Iteration: 20 - Inference Time: 0.582 sec\n",
      "Iteration: 21 - Inference Time: 0.557 sec\n",
      "Iteration: 22 - Inference Time: 0.597 sec\n",
      "Iteration: 23 - Inference Time: 0.631 sec\n",
      "Iteration: 24 - Inference Time: 0.580 sec\n",
      "Iteration: 25 - Inference Time: 0.562 sec\n",
      "Iteration: 26 - Inference Time: 0.557 sec\n",
      "Iteration: 27 - Inference Time: 0.561 sec\n",
      "Iteration: 28 - Inference Time: 0.550 sec\n",
      "Iteration: 29 - Inference Time: 0.560 sec\n",
      "Iteration: 30 - Inference Time: 0.555 sec\n",
      "Iteration: 31 - Inference Time: 0.562 sec\n",
      "Iteration: 32 - Inference Time: 0.569 sec\n",
      "Iteration: 33 - Inference Time: 0.556 sec\n",
      "Iteration: 34 - Inference Time: 0.556 sec\n",
      "Iteration: 35 - Inference Time: 0.549 sec\n",
      "Iteration: 36 - Inference Time: 0.551 sec\n",
      "Iteration: 37 - Inference Time: 0.570 sec\n",
      "Iteration: 38 - Inference Time: 0.553 sec\n",
      "Iteration: 39 - Inference Time: 0.572 sec\n",
      "Iteration: 40 - Inference Time: 0.586 sec\n",
      "Iteration: 41 - Inference Time: 0.571 sec\n",
      "Iteration: 42 - Inference Time: 0.568 sec\n",
      "Iteration: 43 - Inference Time: 0.595 sec\n",
      "Iteration: 44 - Inference Time: 0.558 sec\n",
      "Iteration: 45 - Inference Time: 0.561 sec\n",
      "Iteration: 46 - Inference Time: 0.551 sec\n",
      "Iteration: 47 - Inference Time: 0.550 sec\n",
      "Iteration: 48 - Inference Time: 0.558 sec\n",
      "Iteration: 49 - Inference Time: 0.569 sec\n",
      "Iteration: 50 - Inference Time: 0.548 sec\n",
      "Iteration: 51 - Inference Time: 0.551 sec\n",
      "Iteration: 52 - Inference Time: 0.568 sec\n",
      "Iteration: 53 - Inference Time: 0.572 sec\n",
      "Iteration: 54 - Inference Time: 0.591 sec\n",
      "Iteration: 55 - Inference Time: 0.557 sec\n",
      "Iteration: 56 - Inference Time: 0.578 sec\n",
      "Iteration: 57 - Inference Time: 0.559 sec\n",
      "Iteration: 58 - Inference Time: 0.558 sec\n",
      "Iteration: 59 - Inference Time: 0.563 sec\n",
      "Iteration: 60 - Inference Time: 0.563 sec\n",
      "Iteration: 61 - Inference Time: 0.567 sec\n",
      "Iteration: 62 - Inference Time: 0.577 sec\n",
      "Iteration: 63 - Inference Time: 0.602 sec\n",
      "Iteration: 64 - Inference Time: 0.553 sec\n",
      "Iteration: 65 - Inference Time: 0.565 sec\n",
      "Iteration: 66 - Inference Time: 0.560 sec\n",
      "Iteration: 67 - Inference Time: 0.551 sec\n",
      "Iteration: 68 - Inference Time: 0.550 sec\n",
      "Iteration: 69 - Inference Time: 0.549 sec\n",
      "Iteration: 70 - Inference Time: 0.575 sec\n",
      "Iteration: 71 - Inference Time: 0.568 sec\n",
      "Iteration: 72 - Inference Time: 0.557 sec\n",
      "Iteration: 73 - Inference Time: 0.562 sec\n",
      "Iteration: 74 - Inference Time: 0.593 sec\n",
      "Iteration: 75 - Inference Time: 0.568 sec\n",
      "Iteration: 76 - Inference Time: 0.577 sec\n",
      "Iteration: 77 - Inference Time: 0.578 sec\n",
      "Iteration: 78 - Inference Time: 0.603 sec\n",
      "Iteration: 79 - Inference Time: 0.563 sec\n",
      "Iteration: 80 - Inference Time: 0.596 sec\n",
      "Iteration: 81 - Inference Time: 0.556 sec\n",
      "Iteration: 82 - Inference Time: 0.554 sec\n",
      "Iteration: 83 - Inference Time: 0.567 sec\n",
      "Iteration: 84 - Inference Time: 0.576 sec\n",
      "Iteration: 85 - Inference Time: 0.560 sec\n",
      "Iteration: 86 - Inference Time: 0.595 sec\n",
      "Iteration: 87 - Inference Time: 0.557 sec\n",
      "Iteration: 88 - Inference Time: 0.615 sec\n",
      "Iteration: 89 - Inference Time: 0.599 sec\n",
      "Iteration: 90 - Inference Time: 0.621 sec\n",
      "Iteration: 91 - Inference Time: 0.583 sec\n",
      "Iteration: 92 - Inference Time: 0.569 sec\n",
      "Iteration: 93 - Inference Time: 0.559 sec\n",
      "Iteration: 94 - Inference Time: 0.568 sec\n",
      "Iteration: 95 - Inference Time: 0.545 sec\n",
      "Iteration: 96 - Inference Time: 0.571 sec\n",
      "Iteration: 97 - Inference Time: 0.549 sec\n",
      "Iteration: 98 - Inference Time: 0.566 sec\n",
      "Iteration: 99 - Inference Time: 0.584 sec\n",
      "Iteration: 100 - Inference Time: 0.572 sec\n",
      "Iteration: 101 - Inference Time: 0.571 sec\n",
      "Iteration: 102 - Inference Time: 0.576 sec\n",
      "Iteration: 103 - Inference Time: 0.587 sec\n",
      "Iteration: 104 - Inference Time: 0.559 sec\n",
      "Batch size = 1\n",
      "Latency: 570.160 ms\n",
      "Throughput: 1.754 images/sec\n"
     ]
    }
   ],
   "source": [
    "! python ./scripts/benchmark.py -m ./pre-trained-models/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/optimized_model_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b977f-a465-4969-a4fa-e19762e12a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## analyzing original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeaf8a8-4367-4853-9f42-b1820d011639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72473c6f-9806-4191-b630-c01a8f5c1005",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ## analyzing optimized file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce23717f-373c-47d2-a9a4-cbd0dfea21b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb88e7-b446-4e87-873a-a23bbba8bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "988f1483-3096-4568-b838-1998230ef94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: onnx_export: command not found\n"
     ]
    }
   ],
   "source": [
    " ! onnx_export --input_model pre-trained-models/fineTuned_Model/saved_model/saved_model.pb --output_model pre-trained-models/fineTuned_Model/saved_model/optimised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c522966-925a-4185-b0ef-628325dfa347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 22:50:28 [WARNING] Output tensor names should not be empty.\n",
      "2023-06-29 22:50:28 [WARNING] Input tensor names is empty.\n",
      "2023-06-29 22:50:28 [INFO] Start auto tuning.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Detected evaluation dataloader but no evaluation metric, Please provide both to perform tuning process or neither for the default quantization.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m, dataset\u001b[38;5;241m=\u001b[39mdataset)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneural_compressor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fit\n\u001b[0;32m----> 9\u001b[0m q_model \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpre-trained-models/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPostTrainingQuantConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcalib_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/neural_compressor/quantization.py:189\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, conf, calib_dataloader, calib_func, eval_func, eval_dataloader, eval_metric, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m eval_dataloader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuantize model without tuning!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 189\u001b[0m strategy \u001b[38;5;241m=\u001b[39m \u001b[43mSTRATEGIES\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstrategy_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrapped_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalib_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalib_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_resume\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    199\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m time_limit(conf\u001b[38;5;241m.\u001b[39mtuning_criterion\u001b[38;5;241m.\u001b[39mtimeout):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/neural_compressor/strategy/strategy.py:92\u001b[0m, in \u001b[0;36mTuneStrategyMeta.__call__\u001b[0;34m(cls, pre_strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, pre_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create new strategy instance based on the previous one if has.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m        The newly created strategy instance.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     new_strategy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pre_strategy:\n\u001b[1;32m     94\u001b[0m         new_strategy\u001b[38;5;241m.\u001b[39madaptor \u001b[38;5;241m=\u001b[39m pre_strategy\u001b[38;5;241m.\u001b[39madaptor\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/neural_compressor/strategy/auto.py:56\u001b[0m, in \u001b[0;36mAutoTuneStrategy.__init__\u001b[0;34m(self, model, conf, q_dataloader, q_func, eval_func, eval_dataloader, eval_metric, resume, q_hooks)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     31\u001b[0m              model,\n\u001b[1;32m     32\u001b[0m              conf,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m              resume\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     39\u001b[0m              q_hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Init an auto tuning strategy.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m            on_step_end. Their values are functions to be executed in adaptor layer.. Defaults to None.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mq_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mq_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                     \u001b[49m\u001b[43meval_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                     \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m                     \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mq_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq_hooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** Initialize auto tuning\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategies_sequence \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconservative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbasic\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/neural_compressor/strategy/strategy.py:150\u001b[0m, in \u001b[0;36mTuneStrategy.__init__\u001b[0;34m(self, model, conf, q_dataloader, q_func, eval_func, eval_dataloader, eval_metric, resume, q_hooks)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# not tuning equals to performance only in 1.x\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_not_tuning \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_tuning_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_func \u001b[38;5;241m=\u001b[39m q_func\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_hooks \u001b[38;5;241m=\u001b[39m q_hooks\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/neural_compressor/strategy/strategy.py:348\u001b[0m, in \u001b[0;36mTuneStrategy._check_tuning_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;66;03m# got eval dataloader but not eval metric\u001b[39;00m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_dataloader: \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_metric, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected evaluation dataloader but no evaluation metric, \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    349\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease provide both to perform tuning process or neither for the default quantization.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;66;03m# got eval metric but not eval dataloader\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_metric: \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Detected evaluation dataloader but no evaluation metric, Please provide both to perform tuning process or neither for the default quantization."
     ]
    }
   ],
   "source": [
    "from neural_compressor.config import PostTrainingQuantConfig\n",
    "from neural_compressor.data import DataLoader\n",
    "from neural_compressor.data import Datasets\n",
    "\n",
    "dataset = Datasets('tensorflow')['dummy'](shape=(1, 224, 224, 3))\n",
    "dataloader = DataLoader(framework='tensorflow', dataset=dataset)\n",
    "\n",
    "from neural_compressor.quantization import fit\n",
    "q_model = fit(\n",
    "    model=\"pre-trained-models/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\",\n",
    "    conf=PostTrainingQuantConfig(),\n",
    "    calib_dataloader=dataloader,\n",
    "    eval_dataloader=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9741ad70-8ea3-4aaa-9950-776f12033e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-29 22:51:23--  https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_6/mobilenet_v1_1.0_224_frozen.pb\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.10.208, 64.233.176.128, 192.178.27.208, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.10.208|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16913065 (16M) [application/octet-stream]\n",
      "Saving to: âmobilenet_v1_1.0_224_frozen.pbâ\n",
      "\n",
      "mobilenet_v1_1.0_22 100%[===================>]  16.13M  3.96MB/s    in 4.3s    \n",
      "\n",
      "2023-06-29 22:51:28 (3.77 MB/s) - âmobilenet_v1_1.0_224_frozen.pbâ saved [16913065/16913065]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_6/mobilenet_v1_1.0_224_frozen.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fdb692b-e49e-48bc-b76a-e1fe030d16c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 22:52:25 [WARNING] Output tensor names should not be empty.\n",
      "2023-06-29 22:52:25 [WARNING] Input tensor names is empty.\n",
      "2023-06-29 22:52:25 [INFO] Start auto tuning.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Detected evaluation dataloader but no evaluation metric, Please provide both to perform tuning process or neither for the default quantization.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m, dataset\u001b[38;5;241m=\u001b[39mdataset)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneural_compressor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fit\n\u001b[0;32m----> 9\u001b[0m q_model \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmobilenet_v1_1.0_224_frozen.pb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPostTrainingQuantConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcalib_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/neural_compressor/quantization.py:189\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, conf, calib_dataloader, calib_func, eval_func, eval_dataloader, eval_metric, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m eval_dataloader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuantize model without tuning!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 189\u001b[0m strategy \u001b[38;5;241m=\u001b[39m \u001b[43mSTRATEGIES\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstrategy_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrapped_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalib_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalib_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_resume\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    199\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m time_limit(conf\u001b[38;5;241m.\u001b[39mtuning_criterion\u001b[38;5;241m.\u001b[39mtimeout):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/neural_compressor/strategy/strategy.py:92\u001b[0m, in \u001b[0;36mTuneStrategyMeta.__call__\u001b[0;34m(cls, pre_strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, pre_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create new strategy instance based on the previous one if has.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m        The newly created strategy instance.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     new_strategy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pre_strategy:\n\u001b[1;32m     94\u001b[0m         new_strategy\u001b[38;5;241m.\u001b[39madaptor \u001b[38;5;241m=\u001b[39m pre_strategy\u001b[38;5;241m.\u001b[39madaptor\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/neural_compressor/strategy/auto.py:56\u001b[0m, in \u001b[0;36mAutoTuneStrategy.__init__\u001b[0;34m(self, model, conf, q_dataloader, q_func, eval_func, eval_dataloader, eval_metric, resume, q_hooks)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     31\u001b[0m              model,\n\u001b[1;32m     32\u001b[0m              conf,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m              resume\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     39\u001b[0m              q_hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Init an auto tuning strategy.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m            on_step_end. Their values are functions to be executed in adaptor layer.. Defaults to None.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mq_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mq_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                     \u001b[49m\u001b[43meval_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                     \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m                     \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mq_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq_hooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** Initialize auto tuning\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategies_sequence \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconservative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbasic\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/neural_compressor/strategy/strategy.py:150\u001b[0m, in \u001b[0;36mTuneStrategy.__init__\u001b[0;34m(self, model, conf, q_dataloader, q_func, eval_func, eval_dataloader, eval_metric, resume, q_hooks)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# not tuning equals to performance only in 1.x\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_not_tuning \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_tuning_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_func \u001b[38;5;241m=\u001b[39m q_func\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_hooks \u001b[38;5;241m=\u001b[39m q_hooks\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/neural_compressor/strategy/strategy.py:348\u001b[0m, in \u001b[0;36mTuneStrategy._check_tuning_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;66;03m# got eval dataloader but not eval metric\u001b[39;00m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_dataloader: \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_metric, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected evaluation dataloader but no evaluation metric, \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    349\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease provide both to perform tuning process or neither for the default quantization.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;66;03m# got eval metric but not eval dataloader\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_metric: \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Detected evaluation dataloader but no evaluation metric, Please provide both to perform tuning process or neither for the default quantization."
     ]
    }
   ],
   "source": [
    "from neural_compressor.config import PostTrainingQuantConfig\n",
    "from neural_compressor.data import DataLoader\n",
    "from neural_compressor.data import Datasets\n",
    "\n",
    "dataset = Datasets('tensorflow')['dummy'](shape=(1, 224, 224, 3))\n",
    "dataloader = DataLoader(framework='tensorflow', dataset=dataset)\n",
    "\n",
    "from neural_compressor.quantization import fit\n",
    "q_model = fit(\n",
    "    model=\"mobilenet_v1_1.0_224_frozen.pb\",\n",
    "    conf=PostTrainingQuantConfig(),\n",
    "    calib_dataloader=dataloader,\n",
    "    eval_dataloader=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c147dd18-99f2-4631-8344-134a7818c542",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneural_compressor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchmark\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fit\n\u001b[1;32m      3\u001b[0m conf \u001b[38;5;241m=\u001b[39m BenchmarkConfig(warmup\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, iteration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, cores_per_instance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, num_of_instance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m fit(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre-trained-models/fineTuned_Model/saved_model/saved_model.p\u001b[39m\u001b[38;5;124m'\u001b[39m, conf\u001b[38;5;241m=\u001b[39mconf, b_dataloader\u001b[38;5;241m=\u001b[39m\u001b[43meval_dataloader\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "from neural_compressor.config import BenchmarkConfig\n",
    "from neural_compressor.benchmark import fit\n",
    "conf = BenchmarkConfig(warmup=10, iteration=100, cores_per_instance=4, num_of_instance=7)\n",
    "fit(model='pre-trained-models/fineTuned_Model/saved_model/saved_model.p', conf=conf, b_dataloader=eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be03db-b3aa-40be-b938-6a927188ad6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow (AI kit)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
